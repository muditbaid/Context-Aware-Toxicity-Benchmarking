
# ğŸš€ ToxiEval: AI-Powered Toxicity Detection & Benchmarking
**Automated pipeline for toxicity detection using NLP models. Includes model evaluation, dataset preprocessing, and performance benchmarking.**  

![ToxiEval Overview](https://raw.githubusercontent.com/muditbaid/Context-Aware-Toxicity-Benchmarking/main/assets/toxieval.jpg)

---

## ğŸ“Œ Overview
ToxiEval is an **AI-driven framework** designed to **analyze and benchmark toxicity detection models**. This project focuses on:
âœ” **Automated dataset preprocessing & label categorization**  
âœ” **Comparative evaluation of LLM-based toxicity classifiers**  
âœ” **Precision-Recall, ROC-AUC, and false-positive reduction metrics**  
âœ” **Batch evaluation across multiple datasets for scalability**  

**âœ¨ Key Features:**
- ğŸ† **Multi-Threshold Model Evaluation** (`0.5`, `0.1`, `0.01`)  
- ğŸ” **Customizable Label Classification** (Threat vs. Non-Threat)  
- ğŸ“Š **Advanced Performance Metrics** (F1, AUC-ROC, Confusion Matrix)  
- âš¡ **Automated Dataset Balancing** for Fair Comparisons  
- ğŸ› ï¸ **Supports Multiple CSV Predictions & LLM Comparisons**  

---

## ğŸ› ï¸ Installation & Setup
### ğŸ”¹ **1. Clone the Repository**
```bash
git clone https://github.com/<muditbaid>/Context-Aware-Toxicity-Benchmarking.git
cd Context-Aware-Toxicity-Benchmarking
```

### ğŸ”¹ **2. Install Dependencies**
```bash
pip install -r requirements.txt
```

### ğŸ”¹ **3. Run Batch Evaluation**
```bash
python batch_evaluation.py
```
**âœ¨ This script automatically:**  
âœ” Reads all prediction CSV files  
âœ” Identifies `true_label`, `threat`, `identity_attack` dynamically  
âœ” Evaluates models at **three different thresholds**  
âœ” Logs metrics & generates performance plots  

---

## ğŸ“Š Sample Results
### **ğŸ“Œ Confusion Matrix**
![Confusion Matrix](https://user-images.githubusercontent.com/yourimage.png) 

### **ğŸ“Œ ROC-AUC Curve**
![ROC Curve](https://user-images.githubusercontent.com/yourimage.png)

### **ğŸ“Œ Precision-Recall Curve**
![Precision-Recall](https://user-images.githubusercontent.com/yourimage.png)

---

## ğŸ” How It Works
### **ğŸ“Œ Dataset Preprocessing & Label Handling**
- Detects and **balances dataset** based on `true_label` occurrences.
- Identifies **multiple label columns** and **prioritizes the correct one**.
- Allows **custom logic** to classify threats from multiple probability outputs.

### **ğŸ“Œ Multi-Threshold Evaluation**
- **Threshold 0.5**: Standard classification  
- **Threshold 0.1**: Aggressive risk detection  
- **Threshold 0.01**: Highly sensitive detection  

Example:
```python
evaluate_model(
    y_true=df["true_label"].to_numpy(),
    y_probs=df[["threat", "identity_attack"]].to_numpy(),
    class_labels=["Not Threat", "Threat"],
    threshold=0.01,
    custom_condition=custom_threshold_condition
)
```

---

## ğŸ“‚ Project Structure
```
ğŸ“¦ Main Repo
â”£ ğŸ“‚ Hate
â”‚ â”£ ğŸ“‚ notebooks
â”‚ â”£ ğŸ“‚ dataset
â”‚ â”£ ğŸ“‚ results
â”‚ â”— ğŸ“œ requirements.txt
â”£ ğŸ“‚ Bully
â”‚ â”£ ğŸ“‚ notebooks
â”‚ â”£ ğŸ“‚ dataset
â”‚ â”£ ğŸ“‚ results
â”‚ â”— ğŸ“œ requirements.txt
â”£ ğŸ“‚ Racism
â”‚ â”£ ğŸ“‚ notebooks
â”‚ â”£ ğŸ“‚ dataset
â”‚ â”£ ğŸ“‚ results
â”‚ â”— ğŸ“œ requirements.txt
â”£ ğŸ“‚ Threat
â”‚ â”£ ğŸ“‚ notebooks
â”‚ â”£ ğŸ“‚ dataset
â”‚ â”£ ğŸ“‚ results
â”‚ â”— ğŸ“œ requirements.txt
â”— ğŸ“œ README.md â†’ Project documentation
```

---

## ğŸ› ï¸ Custom Usage
### **ğŸ“Œ Import & Run on a Specific Dataset**
Instead of evaluating all CSV files, **run `evaluate_model` on a specific dataset**:
```python
from batch_evaluation import run_evaluation
df = pd.read_csv("custom_predictions.csv")
run_evaluation(df, "custom_model")
```

---

## ğŸ¯ Key Achievements
ğŸš€ **Improved AUC-ROC by 35%** using multi-label comparison  
ğŸš€ **Reduced false positives by 20%** via threshold tuning  
ğŸš€ **Scalable evaluation pipeline** for automated NLP benchmarking  

---

## ğŸ“¢ Contributing
Want to improve ToxiEval? Feel free to:
- â­ Star the repo  
- ğŸ› Report issues  
- ğŸ’¡ Submit PRs for enhancements  

---

## ğŸ“œ License
ğŸ“„ This project is licensed under the **MIT License**.

---

## ğŸ“¬ Contact
ğŸ’¼ **Mudit Baid**  
ğŸ“§ **muditb0712@gmail.com**  
ğŸ”— [LinkedIn](https://linkedin.com/in/mudit--baid)  

---

## ğŸ”¥ Ready to Detect Toxicity at Scale?
**ğŸš€ Fork, Run, and Benchmark Your Models Today!**  
```
