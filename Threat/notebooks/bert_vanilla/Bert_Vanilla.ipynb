{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654a4902-701e-4b3e-a216-3fbb5f64da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from nltk.stem import PorterStemmer\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm, notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c34f3a86-e4b0-4dfa-8654-7f2fda630746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.MessageMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.ScalarMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model and Tokenizer Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define the path to the BERT model directory\n",
    "MODEL_PATH = \"bert/\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Load the model (make sure config.json is present)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(\"BERT Model and Tokenizer Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc8b562-fa6d-4dc3-8311-4cf79239ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 946.37it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_lines(texts, max_seq_length, tokenizer):\n",
    "    max_seq_length -= 2  # Account for [CLS] and [SEP] tokens\n",
    "    all_tokens = []\n",
    "    for text in tqdm(texts):\n",
    "        tokens_a = tokenizer.tokenize(text)\n",
    "        if len(tokens_a) > max_seq_length:\n",
    "            tokens_a = tokens_a[:max_seq_length]\n",
    "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"] + tokens_a + [\"[SEP]\"]) + [0] * (max_seq_length - len(tokens_a))\n",
    "        all_tokens.append(one_token)\n",
    "    return np.array(all_tokens)\n",
    "\n",
    "# Example usage\n",
    "texts = [\"This is an example sentence.\", \"Another example sentence.\"]\n",
    "MAX_SEQUENCE_LENGTH = 220\n",
    "sequences = convert_lines(texts, MAX_SEQUENCE_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8702fb-02e6-4f88-9521-9526fd503438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55858b89f99e9bda</td>\n",
       "      <td>Hope he dies \\n\\nNow this Atheist filth's wife...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425a1dbdf740e9b8</td>\n",
       "      <td>2006 (UTC)\\n\\n Removed Merge  17:15, 5 April</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20c81b99f7adf557</td>\n",
       "      <td>John discuss it here \\n\\nSeems you don't like ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af0dce6ce84974ec</td>\n",
       "      <td>\"\\nTo answer your question, no. There is no si...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a069e6d6d1a2348d</td>\n",
       "      <td>\"\\n But Arpad can cite any webpage he finds, o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  55858b89f99e9bda  Hope he dies \\n\\nNow this Atheist filth's wife...   \n",
       "1  425a1dbdf740e9b8       2006 (UTC)\\n\\n Removed Merge  17:15, 5 April   \n",
       "2  20c81b99f7adf557  John discuss it here \\n\\nSeems you don't like ...   \n",
       "3  af0dce6ce84974ec  \"\\nTo answer your question, no. There is no si...   \n",
       "4  a069e6d6d1a2348d  \"\\n But Arpad can cite any webpage he finds, o...   \n",
       "\n",
       "   true_label  \n",
       "0           1  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxiccomment = pd.read_csv(\"..//Datasets/toxiccomment/toxiccomment.csv\")\n",
    "toxiccomment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8a3699-6c5d-4316-8317-0c15b690ae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1378/1378 [00:01<00:00, 839.41it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val = convert_lines(toxiccomment['comment_text'].tolist(),MAX_SEQUENCE_LENGTH,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7db2a3c-2bef-47ac-8e81-9c5e1adec89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()  # Frees up GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da5aa9fa-01b3-456b-8787-b70d745b9cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887f2de05d8845d0b8dc456829e1796b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Completed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm  # Use tqdm for progress bar\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "# Prepare DataLoader\n",
    "valid_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.long))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Initialize predictions array\n",
    "valid_preds = np.zeros(len(X_val))\n",
    "\n",
    "# Loop through validation data\n",
    "for i, (x_batch,) in enumerate(tqdm(valid_loader)):\n",
    "    # Forward pass through model\n",
    "    pred = model(x_batch.to(device), attention_mask=(x_batch > 0).to(device))\n",
    "\n",
    "    # Extract logits (predictions)\n",
    "    logits = pred.logits  # Correct way to access outputs\n",
    "\n",
    "    # Store predictions in valid_preds\n",
    "    valid_preds[i * 16 : (i + 1) * 16] = logits[:, 0].detach().cpu().squeeze().numpy()\n",
    "\n",
    "print(\"Inference Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f14bb9-55e0-4355-af40-9125f66b1920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16908528, 0.32328048, 0.20984346, ..., 0.16901615, 0.10675704,\n",
       "       0.32662147])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87fa39ea-b1a2-4ab7-ae37-6bd2d8822d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxiccomment['pred_probability'] = valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef9a2f3-ef71-40f9-947e-937e4592fe3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55858b89f99e9bda</td>\n",
       "      <td>Hope he dies \\n\\nNow this Atheist filth's wife...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.169085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425a1dbdf740e9b8</td>\n",
       "      <td>2006 (UTC)\\n\\n Removed Merge  17:15, 5 April</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20c81b99f7adf557</td>\n",
       "      <td>John discuss it here \\n\\nSeems you don't like ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af0dce6ce84974ec</td>\n",
       "      <td>\"\\nTo answer your question, no. There is no si...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a069e6d6d1a2348d</td>\n",
       "      <td>\"\\n But Arpad can cite any webpage he finds, o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  55858b89f99e9bda  Hope he dies \\n\\nNow this Atheist filth's wife...   \n",
       "1  425a1dbdf740e9b8       2006 (UTC)\\n\\n Removed Merge  17:15, 5 April   \n",
       "2  20c81b99f7adf557  John discuss it here \\n\\nSeems you don't like ...   \n",
       "3  af0dce6ce84974ec  \"\\nTo answer your question, no. There is no si...   \n",
       "4  a069e6d6d1a2348d  \"\\n But Arpad can cite any webpage he finds, o...   \n",
       "\n",
       "   true_label  pred_probability  \n",
       "0           1          0.169085  \n",
       "1           0          0.323280  \n",
       "2           0          0.209843  \n",
       "3           0          0.162970  \n",
       "4           0          0.068898  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxiccomment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b24b6c2-7738-408c-a30d-a7e90ccfd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxiccomment.to_csv('bertvanilla_toxiccomment.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
